{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = np.genfromtxt('sonar.all-data.csv', delimiter=',', dtype=None)\n",
    "dataset = pd.read_csv('sonar.all-data.csv', sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset[60]\n",
    "data = dataset.drop([60], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data[:,0]), np.max(data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'M': 111, 'R': 97})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustar labels para -1 e 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoded_labels = pd.Series(encoder.fit_transform(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels[encoded_labels == 0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# K-fold CrossValidation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_samples(X,y,weights, size):\n",
    "    selected_X = []\n",
    "    selected_y = []\n",
    "    \n",
    "    for new_element in range(size):\n",
    "        sorted_pivot = random.uniform(0, 1)\n",
    "        accum_weight = 0\n",
    "        selected_index = 0\n",
    "\n",
    "        for eval_element in zip(X,y, weights):\n",
    "            X_element = eval_element[0]\n",
    "            y_element = eval_element[1]\n",
    "            weight_element = eval_element[2]            \n",
    "            accum_weight += weight_element\n",
    "            \n",
    "            if sorted_pivot <= accum_weight:\n",
    "                selected_X.append(X_element)\n",
    "                selected_y.append(y_element)\n",
    "                break\n",
    "    return selected_X, selected_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_weights(sample_weights, correct_predictions, incorrect_predictions):\n",
    "    #calcula beta\n",
    "    total_error = np.sum(sample_weights[incorrect_predictions])\n",
    "    beta = 0.5 * np.log( (1 - total_error) / float(total_error))\n",
    "    \n",
    "    #ajusta pesos\n",
    "    sample_weights[incorrect_predictions] = sample_weights[incorrect_predictions] * np.exp(beta)\n",
    "    sample_weights[correct_predictions] = sample_weights[correct_predictions] * np.exp(np.multiply(-1, beta))\n",
    "\n",
    "    #normaliza pesos\n",
    "    total_weight = np.sum(sample_weights)\n",
    "    sample_weights = sample_weights / total_weight\n",
    "    \n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models[0] = DecisionTreeClassifier()\n",
    "models[1] = MLPClassifier()\n",
    "models[2] = MLPClassifier()\n",
    "\n",
    "performance = {\n",
    "    'acuracia': [],\n",
    "    'recall': [],\n",
    "    'precisao': []\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "num_samples = 10\n",
    "random_state=30\n",
    "\n",
    "data, encoded_labels = shuffle(data, encoded_labels, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validação Cruzada - Fold 1\n",
      "Conjunto de treinamento - Dados (187, 60) - (187,)\n",
      "Conjunto de teste - Dados (21, 60) - (21,)\n",
      "____________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "MLPClassifier\n",
      "MLPClassifier\n",
      "Métricas - Fold 1\n",
      "Acurácia: 0.4\n",
      "Recall: 0.0\n",
      "Precision: 0.0\n",
      "############################################################################\n",
      "############################################################################\n",
      "Validação Cruzada - Fold 2\n",
      "Conjunto de treinamento - Dados (187, 60) - (187,)\n",
      "Conjunto de teste - Dados (21, 60) - (21,)\n",
      "____________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "MLPClassifier\n",
      "MLPClassifier\n",
      "Métricas - Fold 2\n",
      "Acurácia: 0.6\n",
      "Recall: 0.3333333333333333\n",
      "Precision: 0.3333333333333333\n",
      "############################################################################\n",
      "############################################################################\n",
      "Validação Cruzada - Fold 3\n",
      "Conjunto de treinamento - Dados (187, 60) - (187,)\n",
      "Conjunto de teste - Dados (21, 60) - (21,)\n",
      "____________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "MLPClassifier\n",
      "MLPClassifier\n",
      "Métricas - Fold 3\n",
      "Acurácia: 0.8\n",
      "Recall: 0.6666666666666666\n",
      "Precision: 0.6666666666666666\n",
      "############################################################################\n",
      "############################################################################\n",
      "Validação Cruzada - Fold 4\n",
      "Conjunto de treinamento - Dados (187, 60) - (187,)\n",
      "Conjunto de teste - Dados (21, 60) - (21,)\n",
      "____________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "MLPClassifier\n",
      "MLPClassifier\n",
      "Métricas - Fold 4\n",
      "Acurácia: 0.6\n",
      "Recall: 0.0\n",
      "Precision: 0.0\n",
      "############################################################################\n",
      "############################################################################\n",
      "Validação Cruzada - Fold 5\n",
      "Conjunto de treinamento - Dados (187, 60) - (187,)\n",
      "Conjunto de teste - Dados (21, 60) - (21,)\n",
      "____________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "MLPClassifier\n",
      "MLPClassifier\n",
      "Métricas - Fold 5\n",
      "Acurácia: 0.6\n",
      "Recall: 0.0\n",
      "Precision: 0.0\n",
      "############################################################################\n",
      "############################################################################\n",
      "Validação Cruzada - Fold 6\n",
      "Conjunto de treinamento - Dados (187, 60) - (187,)\n",
      "Conjunto de teste - Dados (21, 60) - (21,)\n",
      "____________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "MLPClassifier\n",
      "MLPClassifier\n",
      "Métricas - Fold 6\n",
      "Acurácia: 0.7\n",
      "Recall: 0.3333333333333333\n",
      "Precision: 0.5\n",
      "############################################################################\n",
      "############################################################################\n",
      "Validação Cruzada - Fold 7\n",
      "Conjunto de treinamento - Dados (187, 60) - (187,)\n",
      "Conjunto de teste - Dados (21, 60) - (21,)\n",
      "____________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "MLPClassifier\n",
      "MLPClassifier\n",
      "Métricas - Fold 7\n",
      "Acurácia: 0.8\n",
      "Recall: 0.6666666666666666\n",
      "Precision: 0.6666666666666666\n",
      "############################################################################\n",
      "############################################################################\n",
      "Validação Cruzada - Fold 8\n",
      "Conjunto de treinamento - Dados (187, 60) - (187,)\n",
      "Conjunto de teste - Dados (21, 60) - (21,)\n",
      "____________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "MLPClassifier\n",
      "MLPClassifier\n",
      "Métricas - Fold 8\n",
      "Acurácia: 0.8\n",
      "Recall: 0.6666666666666666\n",
      "Precision: 0.6666666666666666\n",
      "############################################################################\n",
      "############################################################################\n",
      "Validação Cruzada - Fold 9\n",
      "Conjunto de treinamento - Dados (188, 60) - (188,)\n",
      "Conjunto de teste - Dados (20, 60) - (20,)\n",
      "____________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "MLPClassifier\n",
      "MLPClassifier\n",
      "Métricas - Fold 9\n",
      "Acurácia: 0.8\n",
      "Recall: 0.6666666666666666\n",
      "Precision: 0.6666666666666666\n",
      "############################################################################\n",
      "############################################################################\n",
      "Validação Cruzada - Fold 10\n",
      "Conjunto de treinamento - Dados (188, 60) - (188,)\n",
      "Conjunto de teste - Dados (20, 60) - (20,)\n",
      "____________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "MLPClassifier\n",
      "MLPClassifier\n",
      "Métricas - Fold 10\n",
      "Acurácia: 0.6\n",
      "Recall: 0.3333333333333333\n",
      "Precision: 0.3333333333333333\n",
      "############################################################################\n",
      "############################################################################\n"
     ]
    }
   ],
   "source": [
    "curr_fold = 1\n",
    "for train_index, test_index in kf.split(data):\n",
    "    predictions = []\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = encoded_labels[train_index], encoded_labels[test_index]\n",
    "    \n",
    "    print('Validação Cruzada - Fold {}'.format(curr_fold))\n",
    "    print('Conjunto de treinamento - Dados {} - {}'.format(X_train.shape, y_train.shape))\n",
    "    print('Conjunto de teste - Dados {} - {}'.format(X_test.shape, y_test.shape))\n",
    "    print('____________________________________________________________________________')\n",
    "    \n",
    "    sample_X_train, sample_y_train = resample(X_train,\n",
    "                                              y_train,\n",
    "                                              n_samples = num_samples,\n",
    "                                              random_state = random_state)\n",
    "\n",
    "    #Inicializa pesos\n",
    "    sample_weights = np.ones(num_samples) / num_samples\n",
    "    \n",
    "    for model in models:\n",
    "        print(type(models[model]).__name__)\n",
    "        correct_predictions = []\n",
    "        incorrect_predictions = []\n",
    "        selected_X_train = []\n",
    "        selected_Y_train = []\n",
    "        \n",
    "        \"\"\"\n",
    "        if model == 0:\n",
    "            selected_X_train = sample_X_train\n",
    "            selected_y_train = sample_y_train\n",
    "        else:\n",
    "            selected_X_train, selected_y_train = select_samples(sample_X_train, \n",
    "                                                                sample_y_train, \n",
    "                                                                sample_weights,\n",
    "                                                                 num_samples )\n",
    "        \"\"\"\n",
    "        selected_X_train, selected_y_train = select_samples(sample_X_train, \n",
    "                                                                sample_y_train, \n",
    "                                                                sample_weights,\n",
    "                                                                 num_samples )\n",
    "        models[model].fit(selected_X_train, selected_y_train)\n",
    "        prediction = models[model].predict(selected_X_train)\n",
    "      \n",
    "        #busca índices das predições corretas e incorretas\n",
    "        for results in enumerate(zip(sample_y_train,prediction)):\n",
    "            real_class = results[1][0]\n",
    "            predicted_class = results[1][1]\n",
    "            if real_class != predicted_class:\n",
    "                incorrect_predictions.append(results[0])\n",
    "            else:\n",
    "                correct_predictions.append(results[0])\n",
    "            \n",
    "        sample_weights = adjust_weights(sample_weights, correct_predictions, incorrect_predictions)\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "    predictions = np.vstack(predictions)\n",
    "    for col in range(predictions.shape[1]):\n",
    "        cnt = Counter()\n",
    "        \n",
    "        votes = predictions[:,col]\n",
    "        for vote in votes:\n",
    "            cnt[vote] +=1\n",
    "        \n",
    "        ensemble_predictions.append(cnt.most_common()[0][0])\n",
    "    #for col in range()\n",
    "    \n",
    "    # Cálculo de métricas\n",
    "    ens_acc = accuracy_score(sample_y_train, ensemble_predictions)\n",
    "    ens_recall = recall_score(sample_y_train, ensemble_predictions)\n",
    "    ens_precisao = precision_score(sample_y_train, ensemble_predictions)\n",
    "    \n",
    "    print('Métricas - Fold {}'.format(curr_fold))\n",
    "    print('Acurácia: {}'.format(ens_acc))\n",
    "    print('Recall: {}'.format(ens_recall))\n",
    "    print('Precision: {}'.format(ens_precisao))\n",
    "    print('############################################################################')\n",
    "    \n",
    "    performance['acuracia'].append(ens_acc)\n",
    "    performance['recall'].append(ens_recall)\n",
    "    performance['precisao'].append(ens_precisao)\n",
    "    \n",
    "    curr_fold +=1\n",
    "    \n",
    "    print('############################################################################')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0339943342776204\n"
     ]
    }
   ],
   "source": [
    "X_train_test = ['A','B','C','D','E','F','G','H','I','J']\n",
    "\n",
    "y_train_test = [1,1,1,1,1,1,1,1,1,1]\n",
    "\n",
    "weights = np.array([0.14,0.03,0.07,0.21,0.13,0.04,0.1,0.1,0.15,0.03])\n",
    "\n",
    "sel_X, sel_y = select_samples(X_train, y_train, weights, 10000)\n",
    "\n",
    "print(sample_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{37: 0.1, 165: 0.1, 173: 0.1, 45: 0.1, 140: 0.1, 151: 0.1, 130: 0.1, 53: 0.1, 145: 0.1, 174: 0.1}\n"
     ]
    }
   ],
   "source": [
    "weights = initialize_weights(sample_y_train, num_samples)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
